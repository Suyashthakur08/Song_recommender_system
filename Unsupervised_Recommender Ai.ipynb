{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2936818,"sourceType":"datasetVersion","datasetId":1800580}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/suyashthakur08/song-recommender?scriptVersionId=202626984\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Importing Data**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-22T09:28:05.990233Z","iopub.execute_input":"2024-10-22T09:28:05.991339Z","iopub.status.idle":"2024-10-22T09:28:07.348661Z","shell.execute_reply.started":"2024-10-22T09:28:05.991287Z","shell.execute_reply":"2024-10-22T09:28:07.347289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport plotly.express as px \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:07.350828Z","iopub.execute_input":"2024-10-22T09:28:07.35145Z","iopub.status.idle":"2024-10-22T09:28:10.398283Z","shell.execute_reply.started":"2024-10-22T09:28:07.351396Z","shell.execute_reply":"2024-10-22T09:28:10.396915Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Reading Data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/spotify-dataset/data/data.csv\")\ngenre_data = pd.read_csv('../input/spotify-dataset/data/data_by_genres.csv')\nyear_data = pd.read_csv('../input/spotify-dataset/data/data_by_year.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:10.400167Z","iopub.execute_input":"2024-10-22T09:28:10.401033Z","iopub.status.idle":"2024-10-22T09:28:11.852582Z","shell.execute_reply.started":"2024-10-22T09:28:10.400978Z","shell.execute_reply":"2024-10-22T09:28:11.851332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Cleaning**","metadata":{}},{"cell_type":"code","source":"def preprocess_data(df):\n# Data cleaning, missing value handling, etc.\n    df_cleaned = df.dropna()  # Dropping missing values\n    return df_cleaned\n\ndata=preprocess_data(data)\n\ngenre_data=preprocess_data(genre_data)\n\nyear_data=preprocess_data(year_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:11.855791Z","iopub.execute_input":"2024-10-22T09:28:11.856324Z","iopub.status.idle":"2024-10-22T09:28:11.959655Z","shell.execute_reply.started":"2024-10-22T09:28:11.856267Z","shell.execute_reply":"2024-10-22T09:28:11.958471Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(data.info())","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:11.961092Z","iopub.execute_input":"2024-10-22T09:28:11.961638Z","iopub.status.idle":"2024-10-22T09:28:12.077346Z","shell.execute_reply.started":"2024-10-22T09:28:11.961581Z","shell.execute_reply":"2024-10-22T09:28:12.075398Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.078825Z","iopub.execute_input":"2024-10-22T09:28:12.079308Z","iopub.status.idle":"2024-10-22T09:28:12.112899Z","shell.execute_reply.started":"2024-10-22T09:28:12.079247Z","shell.execute_reply":"2024-10-22T09:28:12.111662Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(genre_data.info())","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.114276Z","iopub.execute_input":"2024-10-22T09:28:12.114728Z","iopub.status.idle":"2024-10-22T09:28:12.134952Z","shell.execute_reply.started":"2024-10-22T09:28:12.114653Z","shell.execute_reply":"2024-10-22T09:28:12.133564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"genre_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.136754Z","iopub.execute_input":"2024-10-22T09:28:12.137143Z","iopub.status.idle":"2024-10-22T09:28:12.160345Z","shell.execute_reply.started":"2024-10-22T09:28:12.137104Z","shell.execute_reply":"2024-10-22T09:28:12.15918Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(year_data.info())","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.161911Z","iopub.execute_input":"2024-10-22T09:28:12.162274Z","iopub.status.idle":"2024-10-22T09:28:12.177315Z","shell.execute_reply.started":"2024-10-22T09:28:12.162237Z","shell.execute_reply":"2024-10-22T09:28:12.176203Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"year_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.18215Z","iopub.execute_input":"2024-10-22T09:28:12.182562Z","iopub.status.idle":"2024-10-22T09:28:12.203747Z","shell.execute_reply.started":"2024-10-22T09:28:12.182521Z","shell.execute_reply":"2024-10-22T09:28:12.202514Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from yellowbrick.target import FeatureCorrelation\n\n# feature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n\n# X, y = data[feature_names], data['popularity']\n\n# # Create a list of the feature names\n# features = np.array(feature_names)\n\n# # Instantiate the visualizer\n# visualizer = FeatureCorrelation(labels=features)\n\n# plt.rcParams['figure.figsize']=(20,20)\n# visualizer.fit(X, y)     # Fit the data to the visualizer\n# visualizer.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.205174Z","iopub.execute_input":"2024-10-22T09:28:12.20569Z","iopub.status.idle":"2024-10-22T09:28:12.218089Z","shell.execute_reply.started":"2024-10-22T09:28:12.205637Z","shell.execute_reply":"2024-10-22T09:28:12.216779Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data Understanding by Visualization and EDA**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Let's assume 'data' is your DataFrame containing the features and 'popularity' as the target\nfeature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n\nX = data[feature_names]\ny = data['popularity']\n\n# Combine X and y into a single DataFrame to compute correlations\ndf = pd.concat([X, y], axis=1)\n\n# Compute the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Plot using Seaborn's heatmap\nplt.figure(figsize=(20, 20))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n\nplt.title('Feature Correlation with Seaborn')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:12.219584Z","iopub.execute_input":"2024-10-22T09:28:12.219976Z","iopub.status.idle":"2024-10-22T09:28:13.845925Z","shell.execute_reply.started":"2024-10-22T09:28:12.219937Z","shell.execute_reply":"2024-10-22T09:28:13.844698Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Correlation With Popularity","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Define the feature names\nfeature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n\n# Extract the features and target\nX = data[feature_names]\ny = data['popularity']\n\n# Compute correlations between each feature and the target 'popularity'\ncorrelations = X.corrwith(y)\n\n# Convert correlations to a DataFrame for plotting\ncorr_df = pd.DataFrame({'Feature': feature_names, 'Correlation': correlations})\n\n# Sort by the absolute value of the correlation for better visualization\ncorr_df = corr_df.reindex(corr_df['Correlation'].sort_values(ascending=False).index)\n\n# Plot using Seaborn's barplot\nplt.figure(figsize=(12, 8))\nsns.barplot(x='Correlation', y='Feature', data=corr_df, palette='coolwarm')\n\nplt.title('Feature Correlation with Popularity')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:13.847454Z","iopub.execute_input":"2024-10-22T09:28:13.847834Z","iopub.status.idle":"2024-10-22T09:28:14.255811Z","shell.execute_reply.started":"2024-10-22T09:28:13.847795Z","shell.execute_reply":"2024-10-22T09:28:14.254788Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Music Over Time","metadata":{}},{"cell_type":"code","source":"def get_decade(year):\n    period_start = int(year/10) * 10\n    decade = '{}s'.format(period_start)\n    return decade\n\ndata['decade'] = data['year'].apply(get_decade)\n\nsns.set(rc={'figure.figsize':(11 ,6)})\nsns.countplot(x='decade', data=data)\nplt.title('Count of Songs per Decade')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:14.257034Z","iopub.execute_input":"2024-10-22T09:28:14.257393Z","iopub.status.idle":"2024-10-22T09:28:15.083781Z","shell.execute_reply.started":"2024-10-22T09:28:14.257331Z","shell.execute_reply":"2024-10-22T09:28:15.082552Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sound_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'valence']\nfig = px.line(year_data, x='year', y=sound_features)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:15.085465Z","iopub.execute_input":"2024-10-22T09:28:15.085962Z","iopub.status.idle":"2024-10-22T09:28:17.169231Z","shell.execute_reply.started":"2024-10-22T09:28:15.085907Z","shell.execute_reply":"2024-10-22T09:28:17.168044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Characteristics of Top 10 Genres","metadata":{}},{"cell_type":"code","source":"top10_genres = genre_data.nlargest(10, 'popularity')\n\nfig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:17.171122Z","iopub.execute_input":"2024-10-22T09:28:17.17154Z","iopub.status.idle":"2024-10-22T09:28:17.299555Z","shell.execute_reply.started":"2024-10-22T09:28:17.171498Z","shell.execute_reply":"2024-10-22T09:28:17.29833Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Clustering Genres with K-Means**","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ncluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10))])\nX = genre_data.select_dtypes(np.number)\ncluster_pipeline.fit(X)\ngenre_data['cluster'] = cluster_pipeline.predict(X)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:17.301077Z","iopub.execute_input":"2024-10-22T09:28:17.301462Z","iopub.status.idle":"2024-10-22T09:28:18.544653Z","shell.execute_reply.started":"2024-10-22T09:28:17.30142Z","shell.execute_reply":"2024-10-22T09:28:18.543654Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing the Clusters with t-SNE\n\nfrom sklearn.manifold import TSNE\n\ntsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=1))])\ngenre_embedding = tsne_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\nprojection['genres'] = genre_data['genres']\nprojection['cluster'] = genre_data['cluster']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:18.546308Z","iopub.execute_input":"2024-10-22T09:28:18.547622Z","iopub.status.idle":"2024-10-22T09:28:34.412587Z","shell.execute_reply.started":"2024-10-22T09:28:18.547565Z","shell.execute_reply":"2024-10-22T09:28:34.4115Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Clustering Songs with K-Means**","metadata":{}},{"cell_type":"code","source":"song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=20, verbose=False))], verbose=False)\nX = data.select_dtypes(np.number)\nnumber_cols = list(X.columns)\nsong_cluster_pipeline.fit(X)\nsong_cluster_labels = song_cluster_pipeline.predict(X)\ndata['cluster_label'] = song_cluster_labels","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:34.413836Z","iopub.execute_input":"2024-10-22T09:28:34.414175Z","iopub.status.idle":"2024-10-22T09:28:43.714216Z","shell.execute_reply.started":"2024-10-22T09:28:34.414139Z","shell.execute_reply":"2024-10-22T09:28:43.713227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing the Clusters with PCA\n\nfrom sklearn.decomposition import PCA\n\npca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\nsong_embedding = pca_pipeline.fit_transform(X)\nprojection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\nprojection['title'] = data['name']\nprojection['cluster'] = data['cluster_label']\n\nfig = px.scatter(\n    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:43.715638Z","iopub.execute_input":"2024-10-22T09:28:43.716498Z","iopub.status.idle":"2024-10-22T09:28:46.057327Z","shell.execute_reply.started":"2024-10-22T09:28:43.716452Z","shell.execute_reply":"2024-10-22T09:28:46.056052Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Build Recommender System**","metadata":{}},{"cell_type":"code","source":"!pip install spotipy","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:28:46.058875Z","iopub.execute_input":"2024-10-22T09:28:46.059267Z","iopub.status.idle":"2024-10-22T09:29:01.802004Z","shell.execute_reply.started":"2024-10-22T09:28:46.059226Z","shell.execute_reply":"2024-10-22T09:29:01.800586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"SPOTIFY_CLIENT_ID\")\nsecret_value_1 = user_secrets.get_secret(\"SPOTIFY_CLIENT_SECRET\")\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom collections import defaultdict\n\nsp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=secret_value_0,\n                                                           client_secret=secret_value_1))\n\ndef find_song(name, year):\n    song_data = defaultdict()\n    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n    if results['tracks']['items'] == []:\n        return None\n\n    results = results['tracks']['items'][0]\n    track_id = results['id']\n    audio_features = sp.audio_features(track_id)[0]\n\n    song_data['name'] = [name]\n    song_data['year'] = [year]\n    song_data['explicit'] = [int(results['explicit'])]\n    song_data['duration_ms'] = [results['duration_ms']]\n    song_data['popularity'] = [results['popularity']]\n\n    for key, value in audio_features.items():\n        song_data[key] = value\n\n    return pd.DataFrame(song_data)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:29:01.803939Z","iopub.execute_input":"2024-10-22T09:29:01.804357Z","iopub.status.idle":"2024-10-22T09:29:02.487063Z","shell.execute_reply.started":"2024-10-22T09:29:01.804312Z","shell.execute_reply":"2024-10-22T09:29:02.485908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nfrom sklearn.metrics import euclidean_distances\nfrom scipy.spatial.distance import cdist\nimport difflib\n\nnumber_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n\n\ndef get_song_data(song, spotify_data):\n    \n    try:\n        #song_data = spotify_data[(spotify_data['name'] == song['name'])].iloc[0]\n        \n        #For recommending songs with name and year.\n        song_data = spotify_data[(spotify_data['name'] == song['name']) & (spotify_data['year'] == song['year'])].iloc[0]\n        \n        return song_data\n    \n    except IndexError:\n        return find_song(song['name'], song['year'])\n        \n\ndef get_mean_vector(song_list, spotify_data):\n    \n    song_vectors = []\n    \n    for song in song_list:\n        song_data = get_song_data(song, spotify_data)\n        if song_data is None:\n            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n            continue\n        song_vector = song_data[number_cols].values\n        song_vectors.append(song_vector)  \n    \n    song_matrix = np.array(list(song_vectors))\n    return np.mean(song_matrix, axis=0)\n\n\ndef flatten_dict_list(dict_list):\n    \n    flattened_dict = defaultdict()\n    for key in dict_list[0].keys():\n        flattened_dict[key] = []\n    \n    for dictionary in dict_list:\n        for key, value in dictionary.items():\n            flattened_dict[key].append(value)\n            \n    return flattened_dict\n\n\ndef recommend_songs( song_list, spotify_data, n_songs=10):\n    \n    metadata_cols = ['name', 'year', 'artists']\n    song_dict = flatten_dict_list(song_list)\n    \n    song_center = get_mean_vector(song_list, spotify_data)\n    scaler = song_cluster_pipeline.steps[0][1]\n    scaled_data = scaler.transform(spotify_data[number_cols])\n    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n    index = list(np.argsort(distances)[:, :n_songs][0])\n    \n    rec_songs = spotify_data.iloc[index]\n    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n    return rec_songs[metadata_cols].to_dict(orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:29:02.488669Z","iopub.execute_input":"2024-10-22T09:29:02.489039Z","iopub.status.idle":"2024-10-22T09:29:02.505909Z","shell.execute_reply.started":"2024-10-22T09:29:02.488998Z","shell.execute_reply":"2024-10-22T09:29:02.504853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Assuming 'df' is your original dataset with the features you want to cluster\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)  # Scale your features\n\n# Apply PCA to reduce dimensions (optional, but useful for high-dimensional data)\npca = PCA(n_components=5)\ndf_pca = pca.fit_transform(df_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:29:02.507754Z","iopub.execute_input":"2024-10-22T09:29:02.508126Z","iopub.status.idle":"2024-10-22T09:29:03.335921Z","shell.execute_reply.started":"2024-10-22T09:29:02.508087Z","shell.execute_reply":"2024-10-22T09:29:03.332147Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Silhouette Score**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_score\n\n# Assuming 'df_pca' is the PCA-transformed data\nkmeans = KMeans(n_clusters=5)  # Create an instance of KMeans\nkmeans.fit(df_pca)             # Fit the model to your data\n\n# Get the cluster labels for each song\nlabels = kmeans.labels_  \n\n# Calculate silhouette score\nsil_score = silhouette_score(df_pca, labels)\n\nprint(f'Silhouette Score: {sil_score}')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T09:29:03.337507Z","iopub.execute_input":"2024-10-22T09:29:03.337891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Davies Bouldin Score**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import davies_bouldin_score\n\ndb_score = davies_bouldin_score(df_pca, labels)\nprint(f'Davies-Bouldin Index: {db_score}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Song Recommendation**","metadata":{}},{"cell_type":"code","source":"recommend_songs([{'name': 'Gods Plan', 'year':2018}],  data)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}